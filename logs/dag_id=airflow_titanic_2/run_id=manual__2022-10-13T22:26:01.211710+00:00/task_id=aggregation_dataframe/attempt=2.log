[2022-10-13T22:33:52.680+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: airflow_titanic_2.aggregation_dataframe manual__2022-10-13T22:26:01.211710+00:00 [queued]>
[2022-10-13T22:33:52.689+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: airflow_titanic_2.aggregation_dataframe manual__2022-10-13T22:26:01.211710+00:00 [queued]>
[2022-10-13T22:33:52.689+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2022-10-13T22:33:52.689+0000] {taskinstance.py:1363} INFO - Starting attempt 2 of 2
[2022-10-13T22:33:52.689+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2022-10-13T22:33:52.702+0000] {taskinstance.py:1383} INFO - Executing <Task(_PythonDecoratedOperator): aggregation_dataframe> on 2022-10-13 22:26:01.211710+00:00
[2022-10-13T22:33:52.709+0000] {standard_task_runner.py:54} INFO - Started process 25813 to run task
[2022-10-13T22:33:52.711+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', '***_titanic_2', 'aggregation_dataframe', 'manual__2022-10-13T22:26:01.211710+00:00', '--job-id', '41', '--raw', '--subdir', 'DAGS_FOLDER/***_titanic_2.py', '--cfg-path', '/tmp/tmpv5knayee']
[2022-10-13T22:33:52.712+0000] {standard_task_runner.py:83} INFO - Job 41: Subtask aggregation_dataframe
[2022-10-13T22:33:52.712+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/***/dags/***_titanic_2.py
[2022-10-13T22:33:52.868+0000] {logging_mixin.py:117} WARNING - /home/***/.local/lib/python3.7/site-packages/***/models/dag.py:3425 RemovedInAirflow3Warning: Param `schedule_interval` is deprecated and will be removed in a future release. Please use `schedule` instead.
[2022-10-13T22:33:55.970+0000] {task_command.py:384} INFO - Running <TaskInstance: airflow_titanic_2.aggregation_dataframe manual__2022-10-13T22:26:01.211710+00:00 [running]> on host 708a74060eb9
[2022-10-13T22:33:56.053+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Marcos Vieira
AIRFLOW_CTX_DAG_ID=***_titanic_2
AIRFLOW_CTX_TASK_ID=aggregation_dataframe
AIRFLOW_CTX_EXECUTION_DATE=2022-10-13T22:26:01.211710+00:00
AIRFLOW_CTX_TRY_NUMBER=2
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-10-13T22:26:01.211710+00:00
[2022-10-13T22:34:02.388+0000] {logging_mixin.py:117} INFO - +--------+------------------+-------------+--------+------------------+-------------+
|Contagem|            Tarifa|SibSp + Parch|Contagem|            Tarifa|SibSp + Parch|
+--------+------------------+-------------+--------+------------------+-------------+
|     347|12.661632564841513|          347|   347.0|12.661632564841513|        347.0|
|      94|106.12579787234041|           94|    94.0|106.12579787234041|         94.0|
|      76| 21.97012105263158|           76|    76.0| 21.97012105263158|         76.0|
|     144|16.118809722222224|          144|   144.0|16.118809722222224|        144.0|
|     122| 67.22612704918033|          122|   122.0| 67.22612704918033|        122.0|
|     108| 19.74178240740741|          108|   108.0| 19.74178240740741|        108.0|
+--------+------------------+-------------+--------+------------------+-------------+
[2022-10-13T22:34:02.389+0000] {python.py:177} INFO - Done. Returned value was: None
[2022-10-13T22:34:02.400+0000] {taskinstance.py:1406} INFO - Marking task as SUCCESS. dag_id=***_titanic_2, task_id=aggregation_dataframe, execution_date=20221013T222601, start_date=20221013T223352, end_date=20221013T223402
[2022-10-13T22:34:02.448+0000] {local_task_job.py:164} INFO - Task exited with return code 0
[2022-10-13T22:34:02.477+0000] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
